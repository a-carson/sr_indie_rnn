# pytorch_lightning==2.0.9
seed_everything: 0


custom:
  project_name: rn_indie_rnn
  use_wandb: false
  experiment_name: ht1_inference
  name: stn

trainer:
  accelerator: cpu
  max_epochs: 0
  log_every_n_steps: 1
  enable_checkpointing: true
  check_val_every_n_epoch: 1

  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        every_n_epochs: 1
        monitor: val_loss
        save_last: true
#    - class_path: pytorch_lightning.callbacks.EarlyStopping
#      init_args:
#        patience: 200
#        min_delta: 1e-4
#        monitor: val_loss_esr
#        stopping_threshold: 1e-4

model:
  class_path: sr_indie_rnn.sr_indie_train.RNNtoSTN
  init_args:
    sample_rate: 44100
    learning_rate: 5e-4
    ckpt_path: './pretrained/ht1_gru64_epoch=217-step=201432.ckpt'

    rnn_model:
      class_path: sr_indie_rnn.modules.RNN
      init_args:
        hidden_size: 64
        cell_type: 'euler_gru'


    loss_module:
      class_path: utils.loss_modules.TimeDomainLoss


data:
  class_path: utils.dataset.RNNDataModule
  init_args:
    train_sequence_length_seconds: 1.0
    val_sequence_length_seconds: 5.0
    test_sequence_length_seconds: 5.0
    batch_size: 16
    train_input: '../../audio_datasets/dist_fx/train/ht1-input.wav'
    train_target: '../../audio_datasets/dist_fx/train/ht1-target.wav'
    val_input: '../../audio_datasets/dist_fx/val/ht1-input.wav'
    val_target: '../../audio_datasets/dist_fx/val/ht1-target.wav'
    test_input: '../../audio_datasets/dist_fx/test/ht1-input.wav'
    test_target: '../../audio_datasets/dist_fx/test/ht1-target.wav'




